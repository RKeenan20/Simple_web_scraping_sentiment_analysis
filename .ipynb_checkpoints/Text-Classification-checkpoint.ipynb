{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Text Classification\n",
    "\n",
    "# Data Science in Python (Mixed Delivery) - COMP47670\n",
    "\n",
    "## Author - Brian Graham\n",
    "\n",
    "## Student Number - 14434712\n",
    "\n",
    "## Date - 27/04/2020\n",
    "\n",
    "The aim of this assignment is to scrape a number of review pages of various companies within 3 chosen industries, and use the data scraped from the web pages to build a model that will predict whether a review is a positive or negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# \n",
    "# Function to perform a cross validation and display the results \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# \n",
    "# Arguments: \n",
    "#     model      - the classifier model being used \n",
    "#     classifier - the name of the classifier being used\n",
    "#     data       - the dataset\n",
    "#     target     - the outcome of each data point\n",
    "#     num_folds  - the number of folds used in the cross validation\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def cross_validation(model, classifier, data, target, num_folds):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # Perform the cross validation\n",
    "    scores = cross_val_score(model, data, target, cv=num_folds)\n",
    "    print(\"Classifier: \"+ classifier +\"\\n\")\n",
    "    \n",
    "    # Display the individual fold classification accuracy\n",
    "    print(\"Individual Fold Scores:\")\n",
    "    for score in scores:\n",
    "        print(\"\\t%.4f\" % float(score))\n",
    "        \n",
    "    # Display the average classification accuracy\n",
    "    print(\"\\nAverage Fold Score:\")\n",
    "    print(\"\\t%.4f\" % float(scores.mean()))\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# \n",
    "# Function to analyse and display the outcome of a classifier versus the actual outcome\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# \n",
    "# Arguments:\n",
    "#     predicted              - the output of the classifier (predicted outcomes)\n",
    "#     actual                 - the actual outcomes from the datasets\n",
    "#     training_category_name - the name of the training dataset\n",
    "#     test_category_name     - the name of the test dataset\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def classifier_performance(predicted, actual, training_category_name, test_category_name):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    # Evaluate the performance of the classifier with various machine learning metrics\n",
    "    accuracy = accuracy_score(actual,predicted)\n",
    "    precision = precision_score(actual,predicted, average=\"weighted\")\n",
    "    recall = recall_score(actual,predicted, average=\"weighted\")\n",
    "    confusion_matrix = confusion_matrix(actual,predicted)\n",
    "    f1_score_pos = f1_score(actual,predicted,pos_label=\"positive\")\n",
    "    f1_score_neg = f1_score(actual,predicted,pos_label=\"negative\")\n",
    "    \n",
    "    # Calculate the average F1-score\n",
    "    f1_score = (float(f1_score_neg) + float(f1_score_pos))/2\n",
    "    \n",
    "    # Calculate the amount of actual positives and negatives to show the balance of the dataset\n",
    "    percentage_pos = format(actual.count(\"positive\")/(actual.count(\"positive\") + actual.count(\"negative\")), \".2%\")\n",
    "    percentage_neg = format(actual.count(\"negative\")/(actual.count(\"positive\") + actual.count(\"negative\")), \".2%\")\n",
    "    \n",
    "    # Print the information to the screen\n",
    "    print(\"Trained on:              \"+ training_category_name)\n",
    "    print(\"Tested on:               \"+ test_category_name +\"\\n\")\n",
    "    \n",
    "    print(\"Number of Positives:     %4d (%6s of total)\" % (int(actual.count(\"positive\")), percentage_pos))\n",
    "    print(\"Number of Negatives:     %4d (%6s of total)\\n\" % (int(actual.count(\"negative\")), percentage_neg))\n",
    "    \n",
    "    print(\"Classification Accuracy: %s\" % format(float(accuracy), \".2%\"))\n",
    "    print(\"Precision:               %s\" % format(float(precision), \".2%\"))\n",
    "    print(\"Recall:                  %s\" % format(float(recall), \".2%\"))\n",
    "    print(\"F1-Score:                %s\\n\" % format(float(f1_score), \".2%\"))\n",
    "    \n",
    "    print(\"Confusion Matrix:        |%4d\\t%4d|\" % (int(confusion_matrix[0][0]), int(confusion_matrix[0][1])))\n",
    "    print(\"                         |%4d\\t%4d|\" % (int(confusion_matrix[1][0]), int(confusion_matrix[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Web Scraping\n",
    "\n",
    "## 1.1. Industry Selection\n",
    "\n",
    "The first step in the assignment is to scrape a number of web pages for reviews on companies in 3 chosen industries.\n",
    "My chosen industries are the Automotive industry, the Cafe industry and the Gym industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries = [\"automotive\",\"cafes\",\"gym\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Industry Home Pages \n",
    "\n",
    "The first step in the web scraping is to scrape the industry home pages for the individual review page URLs associated with each company. \n",
    "The URLs associated with the individual company review pages are conveniently formatted in a reasonably uniform way, all of the same length. This allowed them to be easily appended to a list. This list is then stored in a dictionary with the industry name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "# The unchanging part of the URL when getting the home pages of each of the industries from Yalp.\n",
    "base_url = \"http://mlg.ucd.ie/modules/yalp\"\n",
    "company_urls = {}\n",
    "\n",
    "for industry in industries:\n",
    "    company_links = []\n",
    "    \n",
    "    # Get the web page code in HTML\n",
    "    home_page_html = requests.get(base_url +\"/\"+ industry +\"_list.html\")\n",
    "    parser = bs4.BeautifulSoup(home_page_html.text,\"html.parser\")\n",
    "    \n",
    "    count = 1\n",
    "    \n",
    "    # The character number associated with the start of the URL for each individual company\n",
    "    # This is updated within the loop\n",
    "    start_of_url = 18\n",
    "\n",
    "    # Filter out all the \"h5\" tags, as this is where all the company URLs are.\n",
    "    for match in parser.find_all(\"h5\"):\n",
    "        text = match.get_text()\n",
    "        company_links.append(str(match)[start_of_url:start_of_url + 38])\n",
    "        count += 1    \n",
    "        if count >= 10 and count < 100:\n",
    "            start_of_url = 19\n",
    "        elif count >= 100 and count < 1000:\n",
    "            start_of_url = 20\n",
    "        elif count >= 1000:\n",
    "            start_of_url = 21\n",
    "            \n",
    "    # Enter each list of company URLs for each industry into a dictionary\n",
    "    company_urls.update({industry: company_links})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Scrape Company Review Page\n",
    "\n",
    "The next step is to filter out the review text and ratings on each of the company home pages. This is done in a similar way to previously when scraping the company URLs in 1.2. \n",
    "The outcome from this is a dictionary ***industry_reviews*** that has all the reviews and ratings for each of the industries, accessible by ***industry_reviews[industry]***, where ***industry*** can be [\"***automotive***\", \"***cafes***\", \"***gym***\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_reviews = {}\n",
    "\n",
    "for industry in industries:\n",
    "    htmls = []\n",
    "    review_text = []\n",
    "    ratings = []\n",
    "    \n",
    "    for company_url in company_urls[industry]:\n",
    "        \n",
    "        # Parse the web page for each company\n",
    "        review_page_html = requests.get(base_url +\"/\"+ company_url).text    \n",
    "        parser = bs4.BeautifulSoup(review_page_html,\"html.parser\")\n",
    "        \n",
    "        # Filter out the ratings and reviews by getting the lines with the \"p\" tag\n",
    "        for match in parser.find_all(\"p\"):\n",
    "            \n",
    "            # Find the rating number, with 1-3 being a \"negative\" outcome and 4 or 5 being a \"positive\" outcome\n",
    "            if str(match)[10:16] == \"rating\":\n",
    "                if int(str(match)[28:29]) > 3:\n",
    "                    ratings.append(\"positive\")\n",
    "                else:\n",
    "                    ratings.append(\"negative\")\n",
    " \n",
    "            # Find the review text\n",
    "            if str(match)[10:21] == \"review-text\":\n",
    "                review_text.append(str(match)[23:-4])\n",
    "\n",
    "    # Dictionary of the industries with associated ratings and reviews\n",
    "    industry_reviews.update({industry: {\"Ratings\": ratings, \"Reviews\": review_text}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. \n",
    "\n",
    "## Part 2.1. Pre-Processing \n",
    "\n",
    "Having successfully scraped the desired web pages for their reviews and ratings, the next step is to process the data in such a way that the review text is represented by a set of numerics.\n",
    "\n",
    "### Stop Words\n",
    "\n",
    "Initially, I will investigate the impact of stemming versus lemmatization on the performance of the classifier that will be used. Stemming is the shortening of words, whereas lemmatization is the generalization of words, both with the aim of better correlating similar terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stop_words = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_stop_words = []\n",
    "for stop_word in stop_words:\n",
    "    stemmed_stop_words.append(stemmer.stem(stop_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_stop_words = []\n",
    "for stop_word in stop_words:\n",
    "    lemma_stop_words.append(lemmatizer.lemmatize(stop_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare TF-IDF Vectorizer\n",
    "\n",
    "To give a more reflective view of the review text against the outcome of the review (positive or negative), the Term Frequency Inverse Document Frequency function is used. This weights words based on their frequency, but also decreases weighting to terms that appear in almost every document, as these do not reflect either way on the outcome of the review.\n",
    "\n",
    "The TFIDF function called also performs case conversion, so that all tokens are lowercase, and removes tokens with length less than 2 by default. I also add in the extra argument to remove tokens that occur less than 10 times in the dataset, as these low frequency terms are really outliers that can be very hard to fit in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "stemmed_vectorizer = TFIDF(stop_words=stemmed_stop_words, min_df = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Model Training\n",
    "\n",
    "The next step is to build a training set of data and associated ratings so that the algorithm can attempt to fit different word patterns to a positive or negative outcome.\n",
    "This training data is then mapped to a numerical representation using the TFIDF algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automotive_data = stemmed_vectorizer.fit_transform(industry_reviews[\"automotive\"][\"Reviews\"])\n",
    "cafes_data = stemmed_vectorizer.fit_transform(industry_reviews[\"cafes\"][\"Reviews\"])\n",
    "gym_data = stemmed_vectorizer.fit_transform(industry_reviews[\"gym\"][\"Reviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Classifier Selection\n",
    "\n",
    "I will now pick a classifier to implement my predictive model on. The 3 options given in the assignment specifications for the classifier are:\n",
    "\n",
    "* Naive-Bayes\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "\n",
    "For each classifier, I will evaluate the model using cross-validation, which splits the dataset into *k* segments. *k-1* segments are then used to train the model, with the remaining segment used in testing. This is repeated until all of the segments have been used as a test dataset, and the performance of the model is averaged over these k tests.\n",
    "I will run the classifier for each of the industry categories and see which performs best on average for each of the datasets.\n",
    "\n",
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.9127\n",
      "\t0.9102\n",
      "\t0.8850\n",
      "\t0.8872\n",
      "\t0.9148\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.9020\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes_model = MultinomialNB()\n",
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", automotive_data, industry_reviews[\"automotive\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8254\n",
      "\t0.8504\n",
      "\t0.8200\n",
      "\t0.8095\n",
      "\t0.8596\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8330\n"
     ]
    }
   ],
   "source": [
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", cafes_data, industry_reviews[\"cafes\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8803\n",
      "\t0.9000\n",
      "\t0.8925\n",
      "\t0.8825\n",
      "\t0.8446\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8800\n"
     ]
    }
   ],
   "source": [
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", gym_data, industry_reviews[\"gym\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.9052\n",
      "\t0.9027\n",
      "\t0.8900\n",
      "\t0.8972\n",
      "\t0.9123\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.9015\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr_model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "cross_validation(lr_model, \"Logistic Regression\", automotive_data, industry_reviews[\"automotive\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8180\n",
      "\t0.8728\n",
      "\t0.8475\n",
      "\t0.8221\n",
      "\t0.8571\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8435\n"
     ]
    }
   ],
   "source": [
    "cross_validation(lr_model, \"Logistic Regression\", cafes_data, industry_reviews[\"cafes\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8903\n",
      "\t0.8825\n",
      "\t0.8925\n",
      "\t0.8925\n",
      "\t0.8421\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8800\n"
     ]
    }
   ],
   "source": [
    "cross_validation(lr_model, \"Logistic Regression\", gym_data, industry_reviews[\"gym\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8678\n",
      "\t0.8853\n",
      "\t0.8425\n",
      "\t0.8421\n",
      "\t0.8772\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "cross_validation(random_forest_model, \"Random Forest\", automotive_data, industry_reviews[\"automotive\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8204\n",
      "\t0.8828\n",
      "\t0.8350\n",
      "\t0.8346\n",
      "\t0.8672\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8480\n"
     ]
    }
   ],
   "source": [
    "cross_validation(random_forest_model, \"Random Forest\", cafes_data, industry_reviews[\"cafes\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forest\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8853\n",
      "\t0.8750\n",
      "\t0.8750\n",
      "\t0.8925\n",
      "\t0.8471\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8750\n"
     ]
    }
   ],
   "source": [
    "cross_validation(random_forest_model, \"Random Forest\", gym_data, industry_reviews[\"gym\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the implementation of the 3 classifiers, all of the models perform quite well, with just over 87% accuracy on average for Naive-Bayes and Logistic Regression, and Random Forest achieves just over 86% on average also. However, Random Forest does not perform as well when it comes to runtime, yielding a much longer runtime than the other models. \n",
    "\n",
    "As the performance of Naive-Bayes and Logistic Regression are extremely similar, I will pick Naive-Bayes arbitrarily, disregarding Random Forest mainly due to its runtime, but also its slightly inferior fold score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming vs. Lemmatization\n",
    "\n",
    "Having picked my classifier as Naive-Bayes, I will see whether stemming or lemmatization yields a higher classification accuracy. Having evaluated the model previously on stemming, I will now train and test the model using lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.9102\n",
      "\t0.9077\n",
      "\t0.8800\n",
      "\t0.8872\n",
      "\t0.9148\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.9000\n"
     ]
    }
   ],
   "source": [
    "lemma_vectorizer = TFIDF(stop_words=lemma_stop_words, min_df = 10)\n",
    "lemma_automotive_data = lemma_vectorizer.fit_transform(industry_reviews[\"automotive\"][\"Reviews\"])\n",
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", lemma_automotive_data, industry_reviews[\"automotive\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8229\n",
      "\t0.8454\n",
      "\t0.8225\n",
      "\t0.8070\n",
      "\t0.8571\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8310\n"
     ]
    }
   ],
   "source": [
    "lemma_cafes_data = lemma_vectorizer.fit_transform(industry_reviews[\"cafes\"][\"Reviews\"])\n",
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", lemma_cafes_data, industry_reviews[\"cafes\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive-Bayes\n",
      "\n",
      "Individual Fold Scores:\n",
      "\t0.8853\n",
      "\t0.9025\n",
      "\t0.8975\n",
      "\t0.8825\n",
      "\t0.8446\n",
      "\n",
      "Average Fold Score:\n",
      "\t0.8825\n"
     ]
    }
   ],
   "source": [
    "lemma_gym_data = lemma_vectorizer.fit_transform(industry_reviews[\"gym\"][\"Reviews\"])\n",
    "cross_validation(naive_bayes_model, \"Naive-Bayes\", lemma_gym_data, industry_reviews[\"gym\"][\"Ratings\"], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the difference between the two methods of generalising text are yielding quite similar results, with a difference of just 0.05% on average over the 3 datasets, with stemming performing slightly better than lemmatization.\n",
    "\n",
    "Thus, as there is little difference in this application, I will stick with stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction\n",
    "\n",
    "In the final section, the aim is to train a classifier on 1 of the 3 categories chosen previously in the assignment (automotive, cafes and gym), and test the trained model on the unseen data in the other 2 categories, and see how the model fares.\n",
    "\n",
    "In accordance with the labelling specified in the question, I will denote automotive to be Category A, cafes to be Category B and gym to be Category C.\n",
    "\n",
    "## 3.1. Training on Automotive\n",
    "\n",
    "The model is first trained by giving it both the training data and the actual outcomes for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TFIDF(stop_words=stemmed_stop_words, min_df = 10)\n",
    "\n",
    "automotive_train = vectorizer.fit_transform(industry_reviews[\"automotive\"][\"Reviews\"])\n",
    "\n",
    "naive_bayes_automotive = MultinomialNB()\n",
    "naive_bayes_automotive.fit(automotive_train,industry_reviews[\"automotive\"][\"Ratings\"])\n",
    "naive_bayes_automotive.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having now been trained to predict the outcome of the review (positive or negative) based on the text in the reviews, the predictions are compared with the actual outcomes below to measure how good the classifier is by testing it on unseen data, namely the ***cafes*** and ***gym*** reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Automotive\n",
      "Tested on:               Cafes\n",
      "\n",
      "Number of Positives:     1462 (73.10% of total)\n",
      "Number of Negatives:      538 (26.90% of total)\n",
      "\n",
      "Classification Accuracy: 83.05%\n",
      "Precision:               82.47%\n",
      "Recall:                  83.05%\n",
      "F1-Score:                75.64%\n",
      "\n",
      "Confusion Matrix:        | 279\t 259|\n",
      "                         |  80\t1382|\n"
     ]
    }
   ],
   "source": [
    "predicted_automotive_cafes = naive_bayes_automotive.predict(vectorizer.transform(industry_reviews[\"cafes\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_automotive_cafes, industry_reviews[\"cafes\"][\"Ratings\"], \"Automotive\", \"Cafes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Automotive\n",
      "Tested on:               Gyms\n",
      "\n",
      "Number of Positives:     1299 (64.95% of total)\n",
      "Number of Negatives:      701 (35.05% of total)\n",
      "\n",
      "Classification Accuracy: 85.95%\n",
      "Precision:               86.52%\n",
      "Recall:                  85.95%\n",
      "F1-Score:                83.42%\n",
      "\n",
      "Confusion Matrix:        | 469\t 232|\n",
      "                         |  49\t1250|\n"
     ]
    }
   ],
   "source": [
    "predicted_automotive_gym = naive_bayes_automotive.predict(vectorizer.transform(industry_reviews[\"gym\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_automotive_gym, industry_reviews[\"gym\"][\"Ratings\"], \"Automotive\", \"Gyms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model when tested on the ***cafes*** dataset is reasonably good, with a classification accuracy of over 83%. It is also important to look at the F1-score, as the dataset is unbalanced, with almost 75% of the dataset being a positive outcome, and the F1-score is a more reflective measure of the performance of a classifier on an unbalanced dataset. With an F1-score of about 76%, the imbalance in the dataset does affect the reliability of the classification accuracy, with a drop of over 7%.\n",
    "\n",
    "It is a similar story when classifying the ***gym*** dataset, with a classification accuracy of 86% and a F1-score of over 83%. This dataset is less unbalanced, with 65% of the dataset being positive compared to 73% with ***cafes***.\n",
    "\n",
    "It is worth noting also that the precision and recall in both cases is between 82% and 87%, which is a good reflection on the performance of the classifier. Also, the classifier trained here using the ***automotive*** dataset yields a false-negative rate that is significantly higher than the false-positive rate. In terms of reviews, this does not matter hugely, as the worst thing that could happen would be that a good review is classed as bad, but businesses that are being reviewed would certainly prefer to have more bad reviews classed as positive than the other way around.\n",
    "\n",
    "## 3.2. Training on Cafes\n",
    "\n",
    "Repeating the procedure, training the classifier this time on the ***cafe*** training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafes_train = vectorizer.fit_transform(industry_reviews[\"cafes\"][\"Reviews\"])\n",
    "\n",
    "naive_bayes_cafes = MultinomialNB()\n",
    "naive_bayes_cafes.fit(cafes_train,industry_reviews[\"cafes\"][\"Ratings\"])\n",
    "naive_bayes_cafes.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Cafes\n",
      "Tested on:               Automotive\n",
      "\n",
      "Number of Positives:     1212 (60.60% of total)\n",
      "Number of Negatives:      788 (39.40% of total)\n",
      "\n",
      "Classification Accuracy: 80.50%\n",
      "Precision:               81.05%\n",
      "Recall:                  80.50%\n",
      "F1-Score:                79.91%\n",
      "\n",
      "Confusion Matrix:        | 634\t 154|\n",
      "                         | 236\t 976|\n"
     ]
    }
   ],
   "source": [
    "predicted_cafes_automotive = naive_bayes_cafes.predict(vectorizer.transform(industry_reviews[\"automotive\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_cafes_automotive, industry_reviews[\"automotive\"][\"Ratings\"], \"Cafes\", \"Automotive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Cafes\n",
      "Tested on:               Gym\n",
      "\n",
      "Number of Positives:     1299 (64.95% of total)\n",
      "Number of Negatives:      701 (35.05% of total)\n",
      "\n",
      "Classification Accuracy: 83.90%\n",
      "Precision:               84.79%\n",
      "Recall:                  83.90%\n",
      "F1-Score:                80.61%\n",
      "\n",
      "Confusion Matrix:        | 427\t 274|\n",
      "                         |  48\t1251|\n"
     ]
    }
   ],
   "source": [
    "predicted_cafes_gym = naive_bayes_cafes.predict(vectorizer.transform(industry_reviews[\"gym\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_cafes_gym, industry_reviews[\"gym\"][\"Ratings\"], \"Cafes\", \"Gym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model when tested on the ***automotive*** dataset is good, with a classification accuracy of just over 80%. The F1-score, precision and recall statistics all are around the 80% mark as well.\n",
    "\n",
    "The performance of the model when classifying the ***gym*** dataset is even better, with a classification accuracy of about 84% and a F1-score of over 80%. This dataset is slightly more unbalanced than the ***automotive*** dataset, with 65% of the dataset being positive compared to 60%, although neither would really be classed as unbalanced.\n",
    "\n",
    "The precision and recall of the classifier is also quite good, with figures between 80% to 85% for the tests.\n",
    "\n",
    "Finally, the number of false positives is higher than the number of  false negatives when classifying the ***automotive*** dataset. This would be a bad thing for these automotive companies, where they would have much less positive ratings than they should.\n",
    "\n",
    "## 3.3. Training on Gym\n",
    "\n",
    "Finally, repeating the procedure, training the data on the ***gym*** dataset and testing on ***automotive*** and ***cafes***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_train = vectorizer.fit_transform(industry_reviews[\"gym\"][\"Reviews\"])\n",
    "\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(gym_train,industry_reviews[\"gym\"][\"Ratings\"])\n",
    "naive_bayes_model.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Gym\n",
      "Tested on:               Automotive\n",
      "\n",
      "Number of Positives:     1212 (60.60% of total)\n",
      "Number of Negatives:      788 (39.40% of total)\n",
      "\n",
      "Classification Accuracy: 79.90%\n",
      "Precision:               83.54%\n",
      "Recall:                  79.90%\n",
      "F1-Score:                79.80%\n",
      "\n",
      "Confusion Matrix:        | 729\t  59|\n",
      "                         | 343\t 869|\n"
     ]
    }
   ],
   "source": [
    "predicted_gym_automotive = naive_bayes_model.predict(vectorizer.transform(industry_reviews[\"automotive\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_gym_automotive, industry_reviews[\"automotive\"][\"Ratings\"], \"Gym\", \"Automotive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on:              Gym\n",
      "Tested on:               Cafes\n",
      "\n",
      "Number of Positives:     1462 (73.10% of total)\n",
      "Number of Negatives:      538 (26.90% of total)\n",
      "\n",
      "Classification Accuracy: 86.35%\n",
      "Precision:               86.03%\n",
      "Recall:                  86.35%\n",
      "F1-Score:                81.12%\n",
      "\n",
      "Confusion Matrix:        | 337\t 201|\n",
      "                         |  72\t1390|\n"
     ]
    }
   ],
   "source": [
    "predicted_gym_cafes = naive_bayes_model.predict(vectorizer.transform(industry_reviews[\"cafes\"][\"Reviews\"]))\n",
    "classifier_performance(predicted_gym_cafes, industry_reviews[\"cafes\"][\"Ratings\"], \"Gym\", \"Cafes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the classifier similarly performs well when trained using the ***gym*** dataset, with figures between approximately 80% and 87% for accuracy, precision, recall and F1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
