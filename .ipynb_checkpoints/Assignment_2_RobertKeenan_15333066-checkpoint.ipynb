{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47670 Assignment 2\n",
    "## Robert Keenan 15333066\n",
    "## Date: 27/04/20\n",
    "\n",
    "The aim of this assignment was to scrape a number of customer reviews from a set of websites and to evaluate the performance of a number of text classification algorithms on the data. \n",
    "\n",
    "Firstly, I needed to choose three review categories to scrape the data from on the website http://mlg.ucd.ie/modules/yalp/ and then to store them as 3 separate datasets. For each review stored, the review text and a class label of positive or negative was stored also. \n",
    "\n",
    "The next steps were to run different classification algorithms on the data and compare their performance.\n",
    "\n",
    "## Review Categories\n",
    "The first step was to choose the review categories to complete the assignment on. In this case, I chose the following:\n",
    "\n",
    "- Automotive Category (132 businesses)\n",
    "- Gym Category (122 businesses)\n",
    "- Hotel Category (113 businesses)\n",
    "\n",
    "From here, I needed to set up my program to be able to scrape all of the reviews from each of these datasets and store in appropriate formats. \n",
    "\n",
    "\n",
    "There are 2 steps to be done first. I need to take the categories that are wanted and scrape their links down. \n",
    "Once those have been established, I need to scrape the individual businesses down for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import nltk\n",
    "link = \"http://mlg.ucd.ie/modules/yalp\"\n",
    "\n",
    "\n",
    "######\n",
    "##### FIXME do all of this work manually first and show the corrector that I know what I'm doing and then show \n",
    "##### the functions that I built\n",
    "def get_url_categories(link, categories_wanted):\n",
    "    category_links=[]\n",
    "    review_links = []\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    #Go through the links\n",
    "    for url in soup.find_all('a'):\n",
    "        current_link = url.get('href')\n",
    "        if current_link == 'index.html':\n",
    "            continue\n",
    "        if categories_wanted != None:\n",
    "            if any(category in current_link for category in categories_wanted):\n",
    "                category_links.append('/'+current_link)\n",
    "        #The review links are being done\n",
    "        else:\n",
    "            review_links.append('/'+current_link)\n",
    "    if categories_wanted != None: \n",
    "        return category_links\n",
    "    else:\n",
    "        return review_links\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Now I need to take the reviews out\n",
    "\n",
    "def get_reviews_store(link, category):    \n",
    "    class_labels = []\n",
    "    review_text_sections = []\n",
    "    #Companies\n",
    "    #This will return a list of companies\n",
    "    companies = get_url_categories(link+category, None)\n",
    "    \n",
    "    for company in companies:\n",
    "        #For each company, I need to open the data of the \n",
    "        response = requests.get(link+company)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        #I have now opened the page for the individual company, and now need to look at \n",
    "        \n",
    "        #For each review in the list, I need to take out the text and the score\n",
    "        #If we look at the insepct element, we can see that the class review is used for any reviews in the space\n",
    "        for review in soup.find_all('div', class_ = 'review'):\n",
    "            #I need the rating at the \n",
    "            #Once I'm here I can take the review number and the review text itself\n",
    "            stars = review.find('img')['alt']\n",
    "            #The star is produced like '1-star' so i need to split on the - and take the number\n",
    "            num_stars = int(stars.split('-')[0])\n",
    "            #Negative review\n",
    "            if num_stars < 4:\n",
    "                class_label = -1\n",
    "            #Positive review\n",
    "            else:\n",
    "                class_label = 1\n",
    "            class_labels.append(class_label)\n",
    "            #I need to pull the text out of it now\n",
    "            review_text = review.find('p', class_ = 'review-text')\n",
    "            review_text = review_text.get_text(strip=True)\n",
    "            review_text_sections.append(review_text)\n",
    "    reviews_of_category = (class_labels, review_text_sections)\n",
    "    return reviews_of_category\n",
    "        \n",
    "\n",
    "categories = get_url_categories(link, ['automotive', 'gym', 'hotel'])\n",
    "automotive_reviews = get_reviews_store(link, categories[0])\n",
    "gym_reviews = get_reviews_store(link, categories[1])\n",
    "hotel_reviews = get_reviews_store(link, categories[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have stored the data in 3 separate datasets. They are stored in the form of a tuple with 2 lists for the class labels and the text. I have decided that anything that has less than 4 stars (1,2,3) is a negative review which is stored with a class label of -1 and anything that has 4 or 5 stars is classed as being a positive review and given a class label of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 \n",
    "In terms of the next section, I need to take the 2 datasets, apply suitable preprocessing techniques to create a numeric representation of the data for each review in a category which will allow it to be suitably classified. \n",
    "\n",
    "Following this, I can build a classification model using a classifier and then test with this classifier to obtain classification results using an evaluation method. \n",
    "\n",
    "As we know, the text of the reviews is not numeric but is rather, text. As a result, it is needed to tokenize the text where each token corresponds to an individual word in the review. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "See Tfidf is better than Count because it takes into account how many documents a term appears in. Like if car turned up 100 times in one review, and service turned up 10 times in 10 reviews, service would rank higher in terms of importance than car\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### preprocessing was done to first analyse which was the best performing classifier for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92  0.91  0.925 0.905 0.89  0.89  0.87  0.89  0.89  0.92 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.901"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "stemmer = PorterStemmer()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords = [stemmer.stem(word) for word in stopWords]\n",
    "\n",
    "#As seen from the 19 Introduction to Text Mining\n",
    "def lemma_tokenizer(text):\n",
    "    # use the standard scikit-learn tokenizer first\n",
    "    standard_tokenizer = CountVectorizer().build_tokenizer()\n",
    "    tokens = standard_tokenizer(text)\n",
    "    # then use NLTK to perform lemmatisation on each token\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_tokens = []\n",
    "    for token in tokens:\n",
    "        lemma_tokens.append( lemmatizer.lemmatize(token) )\n",
    "    return lemma_tokens\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lemma_tokenizer, stop_words=stopWords ,min_df = 10)\n",
    "automotive_targets  = automotive_reviews[0]\n",
    "automotive_data = automotive_reviews[1]\n",
    "\n",
    "\n",
    "pipe_NB = make_pipeline(vectorizer, MultinomialNB())\n",
    "automotive_model = pipe_NB.fit(automotive_data, automotive_targets)\n",
    "\n",
    "pipe_RF = make_pipeline(vectorizer, RandomForestClassifier())\n",
    "pipe_RF.fit(automotive_data, automotive_targets)\n",
    "\n",
    "pipe_linear = make_pipeline(vectorizer, linear_model.LogisticRegression())\n",
    "pipe_linear.fit(automotive_data, automotive_targets)\n",
    "\n",
    "scores = cross_val_score(automotive_model, automotive_data, automotive_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92  0.91  0.905 0.915 0.905 0.885 0.875 0.875 0.9   0.925]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9015000000000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_automotive = vectorizer.fit_transform(automotive_data)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "scores = cross_val_score(naive_bayes_model, X_automotive, automotive_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9   0.87  0.9   0.875 0.85  0.84  0.845 0.83  0.85  0.89 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.865"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe_RF, automotive_data, automotive_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92  0.9   0.905 0.895 0.88  0.88  0.86  0.9   0.895 0.915]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8949999999999999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipe_linear, automotive_data, automotive_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can then print a sample number of the terms\n",
    "#print(terms[200:220])\n",
    "#Now that I have the document-term matrix, I need to find the most commonly used words throughout the vectorizer of terms\n",
    "#freqs = X_automotive.sum(axis=0)\n",
    "#freqs\n",
    "\n",
    "# sort the indexes of the array by value, and then reverse it\n",
    "#sorted_term_indexes = freqs.argsort()\n",
    "#sorted_term_indexes = sorted_term_indexes[0, ::-1]\n",
    "# display the top 10 terms\n",
    "#for i in range(10):\n",
    "#    term_index = sorted_term_indexes[0,i]\n",
    "#    print(\"%s = %.2f\" % ( terms[term_index], freqs[0,term_index] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have shown that the Naive Bayes Classifer is the best for the Automotive, I will conside the Naive Bayes for the other 2 categories of the Gym and Hotel reviews as shown below:\n",
    "\n",
    "\n",
    "TODO CONTINUE WITH SAYING THAT I DO THE PREPROCESSING AND THEN I CAN RUN THE PIPE ON THE DATA TO ESTABLISH THE BEST ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.875 0.895 0.895 0.885 0.865 0.92  0.905 0.86  0.835 0.86 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8795"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_data = gym_reviews[1] \n",
    "gym_targets = gym_reviews[0]\n",
    "gym_model = pipe_NB.fit(gym_data, gym_targets)\n",
    "scores = cross_val_score(gym_model, gym_data, gym_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now repeat the process for the Hotel Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.915 0.825 0.885 0.965 0.88  0.835 0.865 0.9   0.88  0.86 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.881"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data = hotel_reviews[1] \n",
    "hotel_targets = hotel_reviews[0]\n",
    "hotel_model = pipe_NB.fit(gym_data, gym_targets)\n",
    "scores = cross_val_score(hotel_model, hotel_data, hotel_targets, cv=10, scoring=\"accuracy\")\n",
    "print(scores)\n",
    "\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Evaluating Classifier Models on other test data\n",
    "In this section, I will need to analyse the performance of the Naive Bayes classifier when it is trained on one category, say Category A, and then tested on category B and C.\n",
    "To do this, I can use the Pipeline from Scikit Learn to firstly establish a model and train it using the .fit() method from Scikit Learn. I can then test the data on other categories using the .predict() method. \n",
    "### Part (i)\n",
    "In Part (i), I will firstly use the model that was trained on the Automotive data called `automotive_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "def obtain_predictions(model, test_data, test_targets):\n",
    "    predictions = model.predict(test_data)\n",
    "    cm = confusion_matrix(test_targets, predictions,labels=[-1,1])\n",
    "    print(classification_report(test_targets, predictions, target_names=[\"Negative Review\",\"Positive Review\"]))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.94      0.82      0.87       701\n",
      "Positive Review       0.91      0.97      0.94      1299\n",
      "\n",
      "       accuracy                           0.92      2000\n",
      "      macro avg       0.92      0.89      0.91      2000\n",
      "   weighted avg       0.92      0.92      0.92      2000\n",
      "\n",
      "[[ 572  129]\n",
      " [  35 1264]]\n"
     ]
    }
   ],
   "source": [
    "obtain_predictions(automotive_model, gym_data, gym_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the confusion matrix above, the following terms are translate as follows:\n",
    "\n",
    "- True Negtive: A review classified as Negative which is actually Negative in reality.\n",
    "- False Negative: A review classified as Negative which is actually Positive in reality.\n",
    "- False Positive: A review classified as Positive which is actually Negative in reality. \n",
    "- True Positive: A review classified as Positive which is actually Positive in reality\n",
    "\n",
    "\n",
    "Note in the above confusion matrix. The first item of the first row is the number of True Negatives, the first value of the 2nd row is the number of False Negatives, the 2nd value of the 2nd row is the number of True Positives and the 2nd value of the 1st row is the number of False Positives. \n",
    "\n",
    "\n",
    "I can also obtain the same for the Category C results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.81      0.86      0.83       824\n",
      "Positive Review       0.90      0.86      0.88      1176\n",
      "\n",
      "       accuracy                           0.86      2000\n",
      "      macro avg       0.85      0.86      0.85      2000\n",
      "   weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "[[ 708  116]\n",
      " [ 168 1008]]\n"
     ]
    }
   ],
   "source": [
    "obtain_predictions(automotive_model, hotel_data, hotel_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (ii)\n",
    "In Part (ii), I will firstly use the model that was trained on the Gym data called `gym_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.70      0.91      0.79       788\n",
      "Positive Review       0.93      0.74      0.83      1212\n",
      "\n",
      "       accuracy                           0.81      2000\n",
      "      macro avg       0.81      0.83      0.81      2000\n",
      "   weighted avg       0.84      0.81      0.81      2000\n",
      "\n",
      "[[721  67]\n",
      " [313 899]]\n"
     ]
    }
   ],
   "source": [
    "obtain_predictions(gym_model, automotive_data, automotive_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.81      0.86      0.83       824\n",
      "Positive Review       0.90      0.86      0.88      1176\n",
      "\n",
      "       accuracy                           0.86      2000\n",
      "      macro avg       0.85      0.86      0.85      2000\n",
      "   weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "[[ 708  116]\n",
      " [ 168 1008]]\n"
     ]
    }
   ],
   "source": [
    "obtain_predictions(gym_model, hotel_data, hotel_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (iii)\n",
    "In this part, I will train the data on the Hotel data and produce a Naive Bayes classifier model called `hotel_model`. From here, I can test on the automotive and gym data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.70      0.91      0.79       788\n",
      "Positive Review       0.93      0.74      0.83      1212\n",
      "\n",
      "       accuracy                           0.81      2000\n",
      "      macro avg       0.81      0.83      0.81      2000\n",
      "   weighted avg       0.84      0.81      0.81      2000\n",
      "\n",
      "[[721  67]\n",
      " [313 899]]\n"
     ]
    }
   ],
   "source": [
    "obtain_predictions(hotel_model, automotive_data, automotive_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtain_predictions(hotel_model, gym_data, gym_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
